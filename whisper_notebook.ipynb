{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GgsLIeU-sxE"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qswiz-Ih-LM_"
   },
   "outputs": [],
   "source": [
    "!pip install faster-whisper\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uisgLBbb-wxP"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from faster_whisper import WhisperModel\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import shutil\n",
    "import signal\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWjertiK-ypP"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = None\n",
    "file_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByokCdp2-1Ol"
   },
   "outputs": [],
   "source": [
    "def is_whatsapp_audio_file(file_path):\n",
    "    whatsapp_audio_extensions = ['.opus']  # Add other WhatsApp audio extensions if needed\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    is_whatsapp_audio = file_extension in whatsapp_audio_extensions\n",
    "    return is_whatsapp_audio\n",
    "\n",
    "def convert_whatsapp_audio_to_mp3(file_path, output_audio_file):\n",
    "    try:\n",
    "        print(f\"Converting WhatsApp audio file to MP3: {file_path}...\")\n",
    "        # Load the WhatsApp audio file (commonly in .opus format)\n",
    "        audio = AudioSegment.from_file(file_path, codec=\"libopus\")\n",
    "        \n",
    "        # Export the audio as an MP3 file\n",
    "        audio.export(output_audio_file, format=\"mp3\")\n",
    "        \n",
    "        print(f\"WhatsApp audio file converted to MP3: {output_audio_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting WhatsApp audio to MP3: {e}\")\n",
    "\n",
    "def check_ffmpeg_installed():\n",
    "    try:\n",
    "        print(\"Checking if FFmpeg is installed...\")\n",
    "        if shutil.which(\"ffprobe\") is None or shutil.which(\"ffmpeg\") is None:\n",
    "            raise RuntimeError(\"ffmpeg or ffprobe not found. Please install FFmpeg and ensure it's in your system's PATH.\")\n",
    "        print(\"FFmpeg is installed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking FFmpeg installation: {e}\")\n",
    "\n",
    "# Function to check if file is a video\n",
    "def is_video_file(file_path):\n",
    "    try:\n",
    "        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']  # Add other video extensions if needed\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        is_video = file_extension in video_extensions\n",
    "        return is_video\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking if file is a video: {e}\")\n",
    "        return False\n",
    "\n",
    "# Function to extract audio from video\n",
    "def extract_audio_from_video(video_file, output_audio_file):\n",
    "    try:\n",
    "        print(f\"Extracting audio from video file: {video_file}...\")\n",
    "        command = ['ffmpeg', '-i', video_file, '-q:a', '0', '-map', 'a', output_audio_file, '-y']\n",
    "        subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(f\"Audio extracted to: {output_audio_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting audio from video: {e}\")\n",
    "\n",
    "    print(f\"Audio extracted from video file: {video_file} and saved at: {output_audio_file}\")\n",
    "\n",
    "def load_model(model_size, compute_type, device):\n",
    "    try:\n",
    "        print(f\"Loading model: {model_size} | Compute type: {compute_type} | Device: {device}...\")\n",
    "        model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
    "        print(f\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_file(file_path, language, model_size, compute_type, beam_size, condition_on_previous_text, word_timestamps, model=None):\n",
    "    global folder_path\n",
    "    try:\n",
    "        if file_path is None:\n",
    "            return \"Please upload a file\", None\n",
    "\n",
    "        global file_name\n",
    "\n",
    "        # Replace spaces in file name with underscores\n",
    "        file_name = os.path.basename(file_path)\n",
    "        print(f\"File name: {file_name}\")\n",
    "\n",
    "        folder_path = os.path.dirname(os.path.dirname(file_path))\n",
    "        print(f\"Folder path: {folder_path}\")\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        model = load_model(model_size, compute_type, device)\n",
    "        if model is None:\n",
    "            return \"Error loading model\", None\n",
    "\n",
    "        if is_video_file(file_path):\n",
    "            audio_file = os.path.splitext(file_path)[0] + \".mp3\"\n",
    "            extract_audio_from_video(file_path, audio_file)\n",
    "            file_path = audio_file\n",
    "\n",
    "        if is_whatsapp_audio_file(file_path):\n",
    "            audio_file = os.path.splitext(file_path)[0] + \".mp3\"\n",
    "            convert_whatsapp_audio_to_mp3(file_path, audio_file)\n",
    "            file_path = audio_file\n",
    "\n",
    "        print(f\"Transcribing {file_path}...\")\n",
    "        segments, info = model.transcribe(file_path, language=language, beam_size=beam_size, condition_on_previous_text=condition_on_previous_text, word_timestamps=word_timestamps)\n",
    "\n",
    "        transcription = \"\"\n",
    "        for segment in segments:\n",
    "            if word_timestamps:\n",
    "                for word in segment.words:\n",
    "                    transcription += f\"{word.start:.2f} -> {word.end:.2f} {word.word}\\n\"\n",
    "            else:\n",
    "                transcription += f\"{segment.text}\\n\"\n",
    "\n",
    "        # Save the transcript immediately\n",
    "        output_path = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}_transcript.txt\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(transcription)\n",
    "        print(f\"Transcription saved to: {output_path}\")\n",
    "\n",
    "        return transcription, output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing file: {e}\")\n",
    "        return \"Error during transcription\", None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_tSakjw-2X8"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4083Q2ZW-8_d"
   },
   "source": [
    "### Legend:\n",
    "- **Model Size**: Larger models are more accurate but slower and require more memory.\n",
    "- **Compute Type**: float16 is faster, float32 is more precise, int8 is fastest but less accurate.\n",
    "- **Beam Size**: Higher values may improve accuracy but increase processing time.\n",
    "- **Condition on Previous Text**: If checked, uses previous text to improve transcription continuity.\n",
    "- **Word-level timestamps**: If checked, provides timestamps for individual words instead of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "language = \"en\" # en, es, fr, de, it\n",
    "model_size = \"base\" # tiny, base, small, medium, large-v3\n",
    "compute_type = \"float32\" # float16, float32, int8\n",
    "beam_size = 5 # 1 - 10\n",
    "condition_on_previous_text = False # True, False\n",
    "word_timestamps = False # True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmrgaPCl9-1P"
   },
   "outputs": [],
   "source": [
    "# Main execution in Colab\n",
    "if __name__ == \"__main__\":\n",
    "    # Check parameters\n",
    "    assert language in [\"en\", \"es\", \"fr\", \"de\", \"it\"], \"Invalid language\"\n",
    "    assert model_size in [\"tiny\", \"base\", \"small\", \"medium\", \"large-v3\"], \"Invalid model size\"\n",
    "    assert compute_type in [\"float16\", \"float32\", \"int8\"], \"Invalid compute type\"\n",
    "    assert 1 <= beam_size <= 10, \"Invalid beam size\"\n",
    "    assert isinstance(condition_on_previous_text, bool), \"Invalid condition_on_previous_text\"\n",
    "    assert isinstance(word_timestamps, bool), \"Invalid word_timestamps\"\n",
    "\n",
    "    # File upload\n",
    "    uploaded = files.upload()\n",
    "    file_path = list(uploaded.keys())[0]\n",
    "\n",
    "    # Transcribe the file\n",
    "    transcription = transcribe_file(file_path, language, model_size, compute_type, beam_size,\n",
    "                                    condition_on_previous_text, word_timestamps)\n",
    "\n",
    "    # Output transcription\n",
    "    print(\"\\nTranscription:\\n\")\n",
    "    print(transcription)\n",
    "\n",
    "    # Download the transcript\n",
    "    files.download(transcription[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
