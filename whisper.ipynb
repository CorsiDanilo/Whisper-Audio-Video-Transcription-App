{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GgsLIeU-sxE"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qswiz-Ih-LM_"
      },
      "outputs": [],
      "source": [
        "# Install faster-whisper\n",
        "!pip install faster-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uisgLBbb-wxP"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWjertiK-ypP"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByokCdp2-1Ol"
      },
      "outputs": [],
      "source": [
        "# Function to check if file is a video\n",
        "def is_video_file(file_path):\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']  # Add other video extensions if needed\n",
        "    file_extension = os.path.splitext(file_path)[1].lower()\n",
        "    return file_extension in video_extensions\n",
        "\n",
        "# Function to extract audio from video\n",
        "def extract_audio_from_video(video_file, output_audio_file):\n",
        "    command = ['ffmpeg', '-i', video_file, '-q:a', '0', '-map', 'a', output_audio_file, '-y']\n",
        "    subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Load model function\n",
        "def load_model(model_size, compute_type, device):\n",
        "    model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "    print(f\"Model loaded: {model_size} | Compute type: {compute_type} | Device: {device}\")\n",
        "    return model\n",
        "\n",
        "# Transcription function\n",
        "def transcribe_file(file_path, language, model_size, compute_type, beam_size, condition_on_previous_text, word_timestamps):\n",
        "    if file_path is None:\n",
        "        return \"Please upload a file\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = load_model(model_size, compute_type, device)\n",
        "\n",
        "    if is_video_file(file_path):\n",
        "        print(f\"Extracting audio from video file: {file_path}...\")\n",
        "        audio_file = os.path.splitext(file_path)[0] + \".mp3\"\n",
        "        extract_audio_from_video(file_path, audio_file)\n",
        "        file_path = audio_file\n",
        "\n",
        "    print(f\"Transcribing {file_path}...\")\n",
        "    segments, info = model.transcribe(file_path, language=language, beam_size=beam_size,\n",
        "                                      condition_on_previous_text=condition_on_previous_text,\n",
        "                                      word_timestamps=word_timestamps)\n",
        "\n",
        "    transcription = \"\"\n",
        "    for segment in segments:\n",
        "        if word_timestamps:\n",
        "            for word in segment.words:\n",
        "                transcription += f\"{word.start:.2f} -> {word.end:.2f} {word.word}\\n\"\n",
        "        else:\n",
        "            transcription += f\"{segment.text}\\n\"\n",
        "\n",
        "    # Save the transcript\n",
        "    output_path = \"transcript.txt\"\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(transcription)\n",
        "\n",
        "    print(\"Transcription completed. Transcript saved as 'transcript.txt'.\")\n",
        "    return transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_tSakjw-2X8"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4083Q2ZW-8_d"
      },
      "source": [
        "### Legend:\n",
        "- **Model Size**: Larger models are more accurate but slower and require more memory.\n",
        "- **Compute Type**: float16 is faster, float32 is more precise, int8 is fastest but less accurate.\n",
        "- **Beam Size**: Higher values may improve accuracy but increase processing time.\n",
        "- **Condition on Previous Text**: If checked, uses previous text to improve transcription continuity.\n",
        "- **Word-level timestamps**: If checked, provides timestamps for individual words instead of sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters\n",
        "language = \"en\" # en, es, fr, de, it\n",
        "model_size = \"large-v3\" # tiny, base, small, medium, large-v3\n",
        "compute_type = \"float16\" # float16, float32, int8\n",
        "beam_size = 10 # 1 - 10\n",
        "condition_on_previous_text = False # True, False\n",
        "word_timestamps = False # True, False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmrgaPCl9-1P"
      },
      "outputs": [],
      "source": [
        "# Main execution in Colab\n",
        "if __name__ == \"__main__\":\n",
        "    # Check parameters\n",
        "    assert language in [\"en\", \"es\", \"fr\", \"de\", \"it\"], \"Invalid language\"\n",
        "    assert model_size in [\"tiny\", \"base\", \"small\", \"medium\", \"large-v3\"], \"Invalid model size\"\n",
        "    assert compute_type in [\"float16\", \"float32\", \"int8\"], \"Invalid compute type\"\n",
        "    assert 1 <= beam_size <= 10, \"Invalid beam size\"\n",
        "    assert isinstance(condition_on_previous_text, bool), \"Invalid condition_on_previous_text\"\n",
        "    assert isinstance(word_timestamps, bool), \"Invalid word_timestamps\"\n",
        "\n",
        "    # File upload\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "\n",
        "    # Transcribe the file\n",
        "    transcription = transcribe_file(file_path, language, model_size, compute_type, beam_size,\n",
        "                                    condition_on_previous_text, word_timestamps)\n",
        "\n",
        "    # Output transcription\n",
        "    print(\"\\nTranscription:\\n\")\n",
        "    print(transcription)\n",
        "\n",
        "    # Download the transcript\n",
        "    files.download('transcript.txt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
